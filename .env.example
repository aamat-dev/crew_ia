# ==============================
# CONFIGURATION LLM - CREW IA
# ==============================

LOG_LEVEL=DEBUG
LOG_TO_STDOUT=1

# Fournisseur et modèle par défaut (utilisé si aucun spécifique à l'agent)
LLM_DEFAULT_PROVIDER=ollama
LLM_DEFAULT_MODEL=llama3.1:8b

# Ordre de fallback : liste séparée par virgules
LLM_FALLBACK_ORDER=ollama,openai

# Paramètres communs aux LLM
LLM_TIMEOUT_S=60
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=1500

# ==============================
# CONFIGURATION PAR AGENT
# ==============================

# Superviseur
SUPERVISOR_PROVIDER=openai
SUPERVISOR_MODEL=gpt-4o-mini

# Exécuteur
EXECUTOR_PROVIDER=ollama
EXECUTOR_MODEL=llama3.1:8b

# (Si besoin plus tard)
# MANAGER_PROVIDER=
# MANAGER_MODEL=

# ==============================
# CONFIGURATION OLLAMA
# ==============================
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.1:8b

# Modèle fallback côté Ollama
OLLAMA_FALLBACK_MODEL=llama3.1:8b

# ==============================
# CONFIGURATION OPENAI
# ==============================
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_BASE_URL=https://api.openai.com/v1

# --- OpenAI backoff / retries (optionnel) ---
OPENAI_MAX_RETRIES=2
OPENAI_BACKOFF_BASE_MS=200
OPENAI_BACKOFF_FACTOR=2.0

# Modèle fallback côté OpenAI
OPENAI_FALLBACK_MODEL=gpt-4o-mini

# --- Estimation de coût (optionnel) : prix par 1K tokens ---
# Exemple pour gpt-4o-mini (valeurs indicatives !) :
OPENAI_PRICE_PROMPT_GPT_4O_MINI_PER_1K=0.005
OPENAI_PRICE_COMPLETION_GPT_4O_MINI_PER_1K=0.015

# ==============================
# CONFIGURATION NOTION
# ==============================
NOTION_API_KEY=your_notion_api_key_here
NOTION_TASKS_DB_ID=replace_with_database_id

# ==============================
# CONFIGURATION STOCKAGE
# ==============================
DB_URL=postgresql://user:password@localhost:5432/crew_ia
ARTIFACTS_DIR=.runs

# ==============================
# PARAMÈTRES PIPELINE
# ==============================
MAX_CONCURRENCY=3
NODE_RETRIES=2
RETRY_BASE_DELAY=1.0

# --- Overrides par rôle (optionnels) ---
SUPERVISOR_PROVIDER=
SUPERVISOR_MODEL=
SUPERVISOR_TIMEOUT_S=40
SUPERVISOR_TEMPERATURE=0.1
SUPERVISOR_MAX_TOKENS=1200

MANAGER_PROVIDER=
MANAGER_MODEL=
MANAGER_TIMEOUT_S=90
MANAGER_TEMPERATURE=0.2
MANAGER_MAX_TOKENS=1500

EXECUTOR_TIMEOUT_S=120
EXECUTOR_TEMPERATURE=0.3
EXECUTOR_MAX_TOKENS=2000
EXECUTOR_PROVIDER=
EXECUTOR_MODEL=

RECRUITER_PROVIDER=
RECRUITER_MODEL=
RECRUITER_TIMEOUT_S=60
RECRUITER_TEMPERATURE=0.2
RECRUITER_MAX_TOKENS=1000

# Logging
LOG_LEVEL=INFO        # DEBUG pour plus de détails
LOG_TO_STDOUT=1       # 1 = logs aussi en console, 0 = fichier uniquement