# ==============================
# CONFIGURATION LLM - CREW IA
# ==============================

# Fournisseur et modèle par défaut (utilisé si aucun spécifique à l'agent)
LLM_DEFAULT_PROVIDER=ollama
LLM_DEFAULT_MODEL=llama3.1:8b

# Ordre de fallback : liste séparée par virgules
LLM_FALLBACK_ORDER=ollama,openai

# Paramètres communs aux LLM
LLM_TIMEOUT_S=60
LLM_TEMPERATURE=0.2
LLM_MAX_TOKENS=1500

# ==============================
# CONFIGURATION PAR AGENT
# ==============================

# Superviseur
SUPERVISOR_PROVIDER=openai
SUPERVISOR_MODEL=gpt-4o-mini

# Exécuteur
EXECUTOR_PROVIDER=ollama
EXECUTOR_MODEL=llama3.1:8b

# (Si besoin plus tard)
# MANAGER_PROVIDER=
# MANAGER_MODEL=

# ==============================
# CONFIGURATION OLLAMA
# ==============================
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=llama3.1:8b

# Modèle fallback côté Ollama
OLLAMA_FALLBACK_MODEL=llama3.1:8b

# ==============================
# CONFIGURATION OPENAI
# ==============================
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_BASE_URL=https://api.openai.com/v1

# Modèle fallback côté OpenAI
OPENAI_FALLBACK_MODEL=gpt-4o-mini

# ==============================
# CONFIGURATION NOTION
# ==============================
NOTION_API_KEY=your_notion_api_key_here
NOTION_TASKS_DB_ID=replace_with_database_id

# ==============================
# CONFIGURATION STOCKAGE
# ==============================
DB_URL=postgresql://user:password@localhost:5432/crew_ia
ARTIFACTS_DIR=.runs

# ==============================
# PARAMÈTRES PIPELINE
# ==============================
MAX_CONCURRENCY=3
NODE_RETRIES=2
RETRY_BASE_DELAY=1.0
