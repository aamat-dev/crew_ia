# ==============================
# Configuration Crew IA - Exemple
# ==============================

# MODELE SUPERVISEUR / MANAGER / EXECUTEUR
# LLM principal (ex: gpt-4, gpt-4o, llama3.1:8b, mistral:7b)
LLM_MODEL=llama3.1:8b

# Utiliser Ollama (1) ou API externe (0)
USE_OLLAMA=1
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# OpenAI API Key (si USE_OLLAMA=0)
OPENAI_API_KEY=your_openai_api_key_here

# ==============================
# CONFIGURATION STOCKAGE
# ==============================

# Notion
NOTION_API_KEY=your_notion_api_key_here
NOTION_TASKS_DB_ID=replace_with_database_id

# Base de données (optionnel)
DB_URL=postgresql://user:password@localhost:5432/crew_ia

# Répertoire où stocker les artefacts générés
ARTIFACTS_DIR=.runs

# ==============================
# PARAMÈTRES PIPELINE
# ==============================

# Nombre maximum de tâches exécutées en parallèle
MAX_CONCURRENCY=3

# Nombre de tentatives par nœud en cas d'erreur
NODE_RETRIES=2

# Délai de base entre deux tentatives (secondes)
RETRY_BASE_DELAY=1.0
